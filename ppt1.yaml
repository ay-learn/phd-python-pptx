#1- title: INTRODUCTION
#1  paragraphs_1:
#1    - Le deep learning ou l'apprentissage profond est une  méthode
#1      d'apprentissage automatique qui permet à une machine d'apprendre à partir
#1      des données en utilisant des réseaux de neurones artificielles.
#1  image_path: "../../images/ais.png"
#1
#1- title: fonctionnement de deep learning
#1  paragraphs_1:
#1    - le fonctionnement de deep learning se base sur des réseaux de neurone
#1      imitant le cerveau humain.
#1  image_path: "../../images/fonctionement_y.png"
#1
#1- title: application de deep learning
#1  paragraphs_1:
#1    - en plein essor depuis une dizaine d'années le deep learning utile dans
#1      divers domaine
#1  # image_path: "../../images/3_nodules.png"
#1
#1- title: RÉSEAUX DE NEURONES ET DEEP LEARNING
#1  paragraphs_1:
#1    - réseau de neurones; structure consiste d un ensemble (couche ) de briques
#1      élémentaire (neurones ) effectuant chacune des opérations simple.
#1    - couche d entrée
#1    - couche de traitement
#1    - couche de sortie
#1  image_path: "../../images/reseuxActicvation.png"
#1
#1- title: mathématique; le calcule d'un neurones
#1  paragraphs_1:
#1    - pp
#1  # image_path: "../../images/3_nodules.png"
#1
#1- title: image et deep learning
#1  paragraphs_1:
#1    - L'apprentissage profond est très efficace pour l'analyse des images soit
#1      classification ou segmentation par 7 étapes à suivre;
#1    - collecte des données
#1    - pré traitement des données
#1    - creation d'un modele de deep learning
#1    - entrainement du modèle
#1    - validation et ajustement
#1    - test du modèle
#1    - déploiement
#1  image_path: "../../images/structure_resnet.png"
#1
#1- title: Exemple de Deep learning dans la pratique
#1  subtitle_1: Relation entre le
#1  paragraphs_1:
#1    - texte par1_b
#1    - texte par2_a
#1  image_path: "../../images/3_nodules.png"
#1
#1- title: LE PROCESSUS DE CRÉATION D'UN MODÈLE IA
#1  subtitle_1: La phase de prétraitement des données
#1  paragraphs_1:
#1    # - comment L'utilisation de l'IA pour la détection et la classification
#1    #   des nodules pulmonaires comporte deux parties essentielles.
#1    - Consiste à détecter un grand nombre de nodules avec une grande sensibilité,
#1      mais cela génère des faux positifs. Ensuite, la phase de détection réduit ces faux positifs.
#1    - Normalisation des nodules pour avoir la même taille, les mêmes canaux de couleur, etc.
#1  image_path: "../../images/model2_a.png"
#1
#1- title: LE PROCESSUS DE CRÉATION D'UN MODÈLE IA
#1  subtitle_2: La phase d'entraînement du modèle
#1  paragraphs_2:
#1    - L'entraînement du modèle sur des images de nodules ou de lésions, par exemple,
#1      modifie les paramètres du modèle pour devenir capable de créer certains motifs
#1      qui révèlent les caractéristiques et les informations contenues dans les images.
#1    - Ensuite, on peut classer ces motifs en certaines classes. Dans notre cas, il s'agit
#1      de la classification binaire, avec deux classes; nodule ou non-nodule.
#1  image_path: "../../images/model2_b.png"
#1
#1- title: LE PROCESSUS DE CRÉATION D'UN MODÈLE IA
#1  subtitle_3: La phase de prédiction
#1  paragraphs_3:
#1    - Lorsqu'une nouvelle image, quelle que soit sa conception ou sa forme, est
#1      introduite dans le modèle, elle est convertie grâce aux couches de CNN pour
#1      devenir plus similaire à l'un des motifs sur lesquels le modèle a été entraîné
#1      pour la comprendre.
#1
#1    # - On commence par créer un modèle qui contient des paramètres aléatoires,
#1    # et cela génère des motifs aléatoires. Cependant, grâce à l'entraînement
#1    # sur des exemples réels bien traités, le modèle devient capable d'extraire
#1    # de petites images contenant des motifs caractérisant les informations
#1    # complexes des nodules. Ainsi, il réduit la complexité des images de
#1    # grande dimension en des images plus petites, pouvant être classifiées
#1    # dans certaines classes.
#1  image_path: "../../images/model2_c.png"


- title: MATÉRIEL ET MÉTHODE
  subtitle_1: "Les en jeu de donnée"
  paragraphs_1:
    # - Bonjour. Merci mon camarade pour ces informations importantes
    #   Maintenant, passons à la partie pratique.
    # - Dans notre étude, nous avons élaboré deux modèles de Deep Learning,
    #   l'un pour détecter les nodules et l'autre pour la classification.
    # - Nous utilisons comme source des images radiologiques annotées par
    #   quatre experts. Ces images proviennent des ensembles de données
    #   LIDC-IDRI et LUNA16, qui sont disponibles en ligne en open source.
    #   Nous avons également créé un ensemble de données appelé TRPMLN.

    - Les ressources utilisées dans notre étude comprenaient des scans CT et
      des annotations provenant du dataset LIDC-IDRI, du dataset LUNA16 et
      TRPMLN.
    - Le dataset LIDC-IDRI est une base de données publique contenant 1018
      scans thoraciques annotés par quatre radiologues experts. Chaque nodule
      pulmonaire est décrit dans un fichier XML qui contient son
      identifiant, ses caractéristiques, et sa région d'intérêt.
    - Nous avons utilisé des ordinateurs équipés de GPUs stockés sur un site
      Web de recherche appelé Kaggle pour effectuer nos analyses.
  image_path: "../../images/martiel.png"

- title: MATÉRIEL ET MÉTHODE.
  subtitle_1: Les jeux de données LUNA16/TRPMLN.
  paragraphs_1:
    - Pour entraîner notres modèles de détection et de classification en
      utilisant deux ensembles de données adaptés et faciliter leur
      utilisation dans le Deep Learning, nous avons utilisé un sous-ensemble
      de données appelé LUNA16 pour la détection des nodules, et nous avons
      créé un sous-ensemble appelé TRPMLN pour classer les nodules de haut
      risque de malignité.
    - LUNA16 contient 6691 nodules annotés dans 888 scans thoraciques.
    - TRPMLN contient 1568 nodules annotés dans 304 scans thoraciques, en
      extrayant les nodules qui ont une moyenne de malignité égale à 3 ou plus
      dans les annotations des quatre experts.
  image_path: "../../images/type_nodules.png"


- title: ARCHITECTURE
  subtitle_1: "CNN & ResNET"
  paragraphs_1:
    # - Comme architecture du modèle, on utilise des couches CNN dans le
    #   framework TensorFlow.
    - Nous avons expérimenté différentes combinaisons de couches et de filtres
      pour trouver la meilleure hyerparameter de CNNs architecture pour notre problème.
    - Pour entraîner le modèle, on utiliser l'optimiseur Adam avec un taux
      d'apprentissage de 0,001, et la fonction de perte s'appelle l'entropie
      croisée binaire.
  image_path: "../../images/architicture.png"

- title: RÉSULTATS DE MODEL DE DÉTECTION
  subtitle_1: "Résultat d'entraînement"
  paragraphs_1:
    # - Nous avons divisé le DATASET en deux parties pour cacher une partie des
    #   données en vue de l'évaluation du modèle, car la validation du modèle sur
    #   de nouveaux candidats nous donne la vraie performance du modèle.
    #
    # - Ces courbes représentent l'état d'entraînement du modèle.
    # - La courbe bleue correspond à la précision obtenue lors de l'entraînement
    #   avec les nodules d'entraînement.
    # - La courbe jaune correspond à la précision obtenue lors de l'évaluation
    #   avec les nodules de test (comme de nouveaux nodules).
    #
    # - L'essentiel est que le graphe de validation atteigne la meilleure valeur.
    #
    # - Il est très important de visualiser l'état d'entraînement, époque par
    #   époque, pour voir si le modèle s'entraîne correctement ou non.
    #
    # - Si la précision est égale à 50%, on parle de prédiction aléatoire, donc
    #   le modèle ne comprend rien.
    # - Si le modèle s'entraîne un peu et que la précision n'augmente pas, on
    #   arrête l'entraînement et on ajuste d'autres hyperparamètres.
    # - Si la courbe d'entraînement augmente et que la courbe de validation
    #   n'augmente pas, le modèle mémorise les nodules au lieu de comprendre le
    #   motif.

    - En examinant les valeurs de l’exactitude et de l’exactitude de validation
      tout au long des étapes d'apprentissage, on constate que le modèle
      acquiert des connaissances, comme le montre l'amélioration progressive
      des précisions d'entraînement et de validation.
    - Le modèle commence avec des précisions relativement plus faibles, autour
      de 64%, avant d'augmenter à plus de 89% et de terminer avec un score de
      87% à la fin de l'entraînement.
    - Cela démontre la capacité affinée du modèle à classer correctement un
      pourcentage considérable de cas.

    # - À l'aide de la fonction de coût, qui calcule l'erreur entre les valeurs
    #   approximées et les valeurs réelles, nous utilisons l'optimisation Adam
    #   pour améliorer l'approximation de ce modèle de Deep-Learning. Cependant,
    #   plusieurs contraintes empêchent l'optimisation des paramètres du modèle.
    #   Pour résoudre cela, nous ajustons les hyperparamètres afin de trouver des
    #   combinaisons permettant de minimiser les erreurs et d'augmenter la
    #   précision.
    # - Nous testons plusieurs modèles un par un, en les entraînant sur un
    #   certain nombre d'époques et en visualisant les résultats. Nous observons
    #   si les performances des modèles s'améliorent au fil du temps en examinant
    #   les courbes d'entraînement et de validation.
    #
    # - À chaque époque, on calcule l'erreur, on essaie d'optimiser cette erreur,
    #   et on teste la performance en utilisant tous les nodules d'entraînement
    #   pour mettre à jour la courbe d'entraînement. Ensuite, on teste le modèle
    #   avec les nodules de test pour mettre à jour la courbe de validation.
    # - Le meilleur modèle que l'on trouve est bien entraîné sur les candidats
    #   qu'il a déjà vus et affiche une performance de 89% sur les candidats
    #   qu'il n'a jamais vus.
  image_path: "../../images/class2.jpg"
  image_position: IMG_RIGHT


- title: RÉSULTATS DE MODÈLE DE DÉTECTION
  subtitle_1: "Matrice de confusion"
  paragraphs_1:
    - L'utilisation des 1339 nodules de test que le modèle n'a pas encore vus
      pour la détection des nodules/lésions se traduit par une matrice de
      confusion.
    # - Pour visualiser la signification de ces nombres, on peut utiliser le
    # diagramme de Sankey.
  image_path : "../../images/ch3_tab1.png"

- title: RÉSULTATS DE MODÈLE DE DÉTECTION
  subtitle_1: "Diagrame de Sankey pour detection"
  # paragraphs_1:
    # - Si l'on passe 882 lésions et 517 nodules à travers le modèle de
    #   détection, on obtient 771 prédictions de vraies lésions et 404
    #   prédictions de vrais nodules.
    # - Malheureusement, le modèle prédit 133 nodules comme étant des lésions et
    #   51 lésions comme étant des nodules.
    # - Comment les erreurs de ces résultats sont exprimées mathématiquement pour
    #   les évaluer et les comparer avec d'autres modèles qui utilisent des
    #   nombres différents de nodules de test.
  image_path : "../../images/sankey_diagram_1.png"


- title: RÉSULTATS DE MODÈLE DE DÉTECTION
  subtitle_1: Métriques d'évaluation
  paragraphs_1:
    - La performance du modèle peut a été évaluée à partir de la matrice de
      confusion, qui permet de calculer des métriques comme la précision, la
      sensibilité (recall) et le F1-Score, en plus de l’exactitude.
    - Ces mesures fournissent un aperçu plus large des performances du modèle,
      notamment quand il y a un déséquilibre des classes.
    - précision   = (VP) / (VP + FP)
      sensibilité = (VP) / (VP + FN)
      F_1-Score   = (2 VP)/(2VP + FP + FN)
  image_path : "../../images/ch3_tab2.png"
  image_position: IMG_RIGHT

- title: DISCUSSION DE MODÈLE DE DÉTECTION
  subtitle_1: Overfitting
  paragraphs_1:
    - L'exactitude de l'entraînement atteint 100 %,ce qui est un signe clair
      de surapprentissage(overfitting), surtout par rapport à l'exactitude de
      validation qui est bien inférieure. Le surajustement signifie que le
      modèle a trop bien appris les données d'entraînement.
    - Pour résoudre les problèmes de Overfitting, il faut augmenter le nombre
      d'échantillons ou utiliser des techniques de Deep Learning, telles que
      des techniques de régularisation comme la technique d'intention.
    - Comparaison avec nos résultats, notre modèle de classification de nodule
      ou lésion est performant de manière compétente dans l'identification des
      deux classes.
    - En général, le modèle a performé de manière impressionnante en termes
      de précision, de sensibilité et de "F1-score".
  image_path : "../../images/ch3_tab6.png"
  image_position: IMG_RIGHT

- title: MODÈLE DE CLASSIFICATION DES NODULE DE HAUT RISQUE DE MALIGNETE
  # subtitle_1: Overfitting
  # paragraphs_1:
  #   - L'exactitude de l'entraînement atteint 100 %,ce qui est un signe clair
  #     de surapprentissage(overfitting), surtout par rapport à l'exactitude de
  #     validation qui est bien inférieure. Le surajustement signifie que le
  #     modèle a trop bien appris les données d'entraînement.
  #   - Pour résoudre les problèmes de Overfitting, il faut augmenter le nombre
  #     d'échantillons ou utiliser des techniques de Deep Learning, telles que
  #     des techniques de régularisation comme la technique d'intention.
  #   - Comparaison avec nos résultats, notre modèle de classification de nodule
  #     ou lésion est performant de manière compétente dans l'identification des
  #     deux classes.
  #   - En général, le modèle a performé de manière impressionnante en termes
  #     de précision, de sensibilité et de "F1-score".
  image_path : "../../images/ch3_tab7.png"
  # image_position: IMG_RIGHT


#3- title: "T2"
#3  subtitle_1: "t2"
#3  paragraphs_1:
#3    - "Pou"
#3  image_path : "../../images/ch3_tab2.png"
#3
#3
#3- title: "Exemple de Deep "
#3  subtitle_1: "Relation entre "
#3  paragraphs_1:
#3    - "Pou"
#3  image_path : "../../images/structure_resnet.png"
#3
#3
#3- title: "Exemple de Deep le"
#3  subtitle_1: "Relation entre les réseaux "
#3  paragraphs_1:
#3    - "Pou"
#3  image_path : "../../images/resnet_model6.png"
